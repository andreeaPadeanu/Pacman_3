# Pacman_3
 reinforcement learning

In this project, we implemented algorithms from the area of reinforcement learning such as value iteration or Q-learning. We made modifications in the files valueIterationAgents.py, qlearningAgents.py, and analysis.py.

Question 1: We implemented a value iteration-based agent in the file valueIterationAgent.py. This agent is offline and trained before the game. The parameter controlling training is the number of iterations in the value iteration algorithm.

Question 2: We analyzed the bridge crossing problem on the BridgeGrid setup to see how the calculated optimal policy allows the agent to cross the bridge.

Question 3: We studied different policies on the DiscountGrid layout to produce optimal policies of different types, using settings for discount, noise, and survival bonus.

Question 4: We implemented a Q-learning agent in the file qlearningAgent.py, which learns from errors and interacts with the environment in the update function.

Question 5: We finalized the implementation of the Q-learning agent by adding an epsilon-greedy action selection strategy in the getAction method.

Question 6: We explored how the optimal policy can be learned by a Q-learning agent for the BridgeGrid problem by adjusting the epsilon and learning rate parameters.

Question 7: We investigated the behavior of the Q-learning agent for Pacman on small layouts and identified a combination of parameters (epsilon and learning rate) that produces a very good chance for the optimal policy to be learned in a timely manner.

Question 8: We ran training and testing games for the Pacman Q-learning agent and evaluated its performance.

Question 9: We implemented an approximate Q-learning agent in the file qlearningAgents.py, which learns weights for state features using approximate Q-learning techniques.




User
persoana 1 singular
ChatGPT
In this project, I implemented algorithms from the area of reinforcement learning such as value iteration or Q-learning. I made modifications in the files valueIterationAgents.py, qlearningAgents.py, and analysis.py.

Question 1: I implemented a value iteration-based agent in the file valueIterationAgent.py. This agent is offline and trained before the game. The parameter controlling training is the number of iterations in the value iteration algorithm.

Question 2: I analyzed the bridge crossing problem on the BridgeGrid setup to see how the calculated optimal policy allows the agent to cross the bridge.

Question 3: I studied different policies on the DiscountGrid layout to produce optimal policies of different types, using settings for discount, noise, and survival bonus.

Question 4: I implemented a Q-learning agent in the file qlearningAgent.py, which learns from errors and interacts with the environment in the update function.

Question 5: I finalized the implementation of the Q-learning agent by adding an epsilon-greedy action selection strategy in the getAction method.

Question 6: I explored how the optimal policy can be learned by a Q-learning agent for the BridgeGrid problem by adjusting the epsilon and learning rate parameters.

Question 7: I investigated the behavior of the Q-learning agent for Pacman on small layouts and identified a combination of parameters (epsilon and learning rate) that produces a very good chance for the optimal policy to be learned in a timely manner.

Question 8: I ran training and testing games for the Pacman Q-learning agent and evaluated its performance.

Question 9: I implemented an approximate Q-learning agent in the file qlearningAgents.py, which learns weights for state features using approximate Q-learning techniques.
